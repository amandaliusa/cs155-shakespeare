{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observations(text):\n",
    "    # Convert text to dataset. Treat each stanza as a sequence.\n",
    "    \n",
    "    line_counter = 0 \n",
    "    lines = [line.strip() for line in text.split('\\n')]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "    obs_elem = []\n",
    "\n",
    "    for line in lines:\n",
    "        # don't include sonnet numbers or blank lines\n",
    "        if len(line) in [1, 2, 3]:\n",
    "            line_counter = 0\n",
    "            continue\n",
    "        elif len(line) == 0:\n",
    "            continue\n",
    "  \n",
    "        words = [word.strip() for word in line.split(' ')]\n",
    "        for word in words:\n",
    "            # make all words lowercase and remove punctuation\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            \n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        line_counter += 1\n",
    "        if line_counter % 4 == 0 or line_counter == 14:\n",
    "            # Add the encoded sequence after end of each stanza\n",
    "            obs.append(obs_elem)\n",
    "            obs_elem = []\n",
    "        \n",
    "    return obs, obs_map\n",
    "\n",
    "def parse_lines(text):\n",
    "    # Convert text to dataset. Treat each line as a sequence.\n",
    "    \n",
    "    lines = [line.strip() for line in text.split('\\n')]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        # don't include sonnet numbers or blank lines\n",
    "        if len(line) in [0, 1, 2, 3]:\n",
    "            continue\n",
    "  \n",
    "        obs_elem = []\n",
    "        words = [word.strip() for word in line.split(' ')]\n",
    "        for word in words:\n",
    "            # make all words lowercase and remove punctuation\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            \n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        obs.append(obs_elem)\n",
    "               \n",
    "    return obs, obs_map\n",
    "\n",
    "def parse_poems(text):\n",
    "    # Convert text to dataset. Treat each poem as a sequence.\n",
    "    \n",
    "    line_counter = 0 \n",
    "    lines = [line.strip() for line in text.split('\\n')]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "    obs_elem = []\n",
    "\n",
    "    for line in lines:\n",
    "        # don't include sonnet numbers or blank lines\n",
    "        if len(line) in [1, 2, 3]:\n",
    "            line_counter = 0\n",
    "            continue\n",
    "        elif len(line) == 0:\n",
    "            continue\n",
    "  \n",
    "        words = [word.strip() for word in line.split(' ')]\n",
    "        for word in words:\n",
    "            # make all words lowercase and remove punctuation\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            \n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "            \n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "        \n",
    "        line_counter += 1\n",
    "        if line_counter == 14:\n",
    "            # Add the encoded sequence after end of each stanza\n",
    "            obs.append(obs_elem)\n",
    "            obs_elem = []\n",
    "        \n",
    "    return obs, obs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(os.path.join(os.getcwd(), 'data/shakespeare.txt')).read()\n",
    "\n",
    "# get words as numbers and get the word map\n",
    "all_words = []\n",
    "words, word_to_int_map = parse_poems(text)\n",
    "for i in range(len(words)):\n",
    "    for j in range(len(words[i])):\n",
    "        all_words.append(words[i][j])\n",
    "words = all_words\n",
    "int_to_word_map = {v: k for k, v in word_to_int_map.items()}\n",
    "\n",
    "\n",
    "# remove sonnet numbers and convert to lowercase\n",
    "n_words = len(words)\n",
    "n_vocab = len(word_to_int_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 7\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "# use sliding window approach\n",
    "for i in range(0, n_words - seq_length, 1):\n",
    "    seq_in = words[i:i + seq_length]\n",
    "    seq_out = words[i + seq_length]\n",
    "    dataX.append([word for word in seq_in])\n",
    "    dataY.append(seq_out)\n",
    "    \n",
    "n_sequences = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_sequences, seq_length, 1))\n",
    "\n",
    "# normalize data to range (0, 1)\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model \n",
    "# (single layer with 150 units, followed by dense output layer)\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights from best checkpoint\n",
    "filename = \"weights-improvement-word-20-6.3359.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temp=1.0):\n",
    "    '''\n",
    "    Helper function for sampling from softmax with different temperatures.\n",
    "    \n",
    "    Inputs:\n",
    "    preds: output of softmax function\n",
    "    temp: temperature to scale by\n",
    "    '''\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temp\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    \n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature 0.1\n",
      "and the the my the the the \n",
      "thy thy and i and my my \n",
      "love and and the thy my the \n",
      "thou the i my thou thy my \n",
      "the my thou thy my thy i \n",
      "my thou i to i to thou \n",
      "thy thy thou my thou thou thy \n",
      "thou thou thy thou thy thou thou \n",
      "thy i my thy thy thy thy \n",
      "my thy thy my and thou thou \n",
      "my thy thou the thy i that \n",
      "my i thy thou the thy thy \n",
      "thy i my thy my my thy \n",
      "thy thou the thou thou thy thy \n",
      "\n",
      "Temperature 0.25\n",
      "thy thou my my the my thee \n",
      "thou thou self thy that a my \n",
      "to i and i and my for \n",
      "the my love that the i thy \n",
      "in my to thou eyes so thy \n",
      "so thy that and i and thy \n",
      "thy the i thou that the the \n",
      "for when my thou the that thou \n",
      "in that that the my and my \n",
      "thou the i thy thou thou my \n",
      "the the that in thou so thy \n",
      "it to and to but that to \n",
      "the i of to my to to \n",
      "that thou the i my in i \n",
      "\n",
      "Temperature 0.75\n",
      "have time i for but a as \n",
      "so that as heat so this mayst \n",
      "spring be good thoughts if thou with \n",
      "thou to times in thy with grief \n",
      "a prove self i so and golden \n",
      "live show that their i my with \n",
      "it a of were thou despise for \n",
      "i the this can and this o \n",
      "though teach with me you straight for \n",
      "groan by for like with i love \n",
      "and hear so hes is herein tender \n",
      "write nor compare eyes thou when beauty \n",
      "my doth in then with do praising \n",
      "i thy my see beauty and to \n",
      "\n",
      "Temperature 1.5\n",
      "others tomb impiety now taught main cheeks \n",
      "makes man grecian wink my swift this \n",
      "canopy reeks and report holds nought thy \n",
      "not coloured rising reign distance commend here \n",
      "decembers saith subtleties your the put tongues \n",
      "root hours sportive are presence i orphans \n",
      "be wood grows niggard entertain why helens \n",
      "make wastes nightly that minutes brave blunt \n",
      "alack return shape my earth sick it \n",
      "that course conspire proudpied being inward mad \n",
      "was fall frowns fell care image strife \n",
      "smells she sacred make burthens hast please \n",
      "yet loving your chopt scope who lusty \n",
      "past thief loathsome temptation is those of \n",
      "\n",
      "Temperature 2\n",
      "bright perforce sure bosoms thought delighted me \n",
      "dove will nurseth no this this wretch \n",
      "moving sunk presence sluttish good well let \n",
      "kiss gross ten in shake forgot tied \n",
      "honour mine neck think than come thus \n",
      "masonry ay suggest broke sleeping false smiling \n",
      "better art make lively tongues growst now \n",
      "gaol public decayed in general triumphant shame \n",
      "we for belongs wild bear policy unlearned \n",
      "forsworn while words writers return growing lose \n",
      "truly alien chronicle report lose process woe \n",
      "own well mortal hath writ ere wished \n",
      "false unmoved second blunting aye given still \n",
      "saw break wolf lease fixed devised father \n",
      "\n",
      "Temperature 2.5\n",
      "mark lap in to outworn poor desire \n",
      "restored befriends of told selling many owners \n",
      "cure receive that wilfulness pitied alloblivious bends \n",
      "perforce ill farther even painting religious their \n",
      "mow ending your stained fulfil lends flattery \n",
      "thee cars up shall believed suborned temperate \n",
      "praise confine lips breath delight convertest for \n",
      "deserves dignified of possession leave but trim \n",
      "belied act debateth into please thy your \n",
      "womens why spend shouldst possesseth land heat \n",
      "eisel restored hast wide seeting wolf who \n",
      "of millions basest truly feel tonguetied heavy \n",
      "summer of hide thrive adonis the whole \n",
      "honour silvered days this to public sacred \n",
      "\n",
      "Temperature 3\n",
      "telling confessed sickness hearts embassage jealousy allege \n",
      "dispraise denote plants ashes longer inhearse distraction \n",
      "bodys scorn rider health lest situation graves \n",
      "worst lovegod knew chronicle consecrate then thing \n",
      "feasts exceeded felt fashion no reason testy \n",
      "impediments taste sooner out thee evermore infection \n",
      "fitted savour and cold makeless liquid yore \n",
      "long comments idly hanging middle gravity knit \n",
      "steepy body faces compounds perpetual wretch should \n",
      "purpose being deserts but forgetst compeers presentabsent \n",
      "tis majesty admitted progress flown fears tune \n",
      "tattered bitter refined prefiguring hold pricked woe \n",
      "forfeit deceived cup return moan think modern \n",
      "low forebemoaned wit do selfsame blenches belong \n",
      "\n",
      "Temperature 5\n",
      "thereof west bait faces embassage life try \n",
      "witness ruth insufficiency semblance brand morrow dressed \n",
      "it into rose excellent suppressed wilfulslow ushers \n",
      "war soil gross workings waking sorrows enforced \n",
      "honest just part hits hasten mourners spend \n",
      "going hungry o captain hours penury boughs \n",
      "pride others rank hits obsequious already substance \n",
      "evil smoke runst lovekindling lines impregnable heavens \n",
      "confounding subject alters wear shapes nor springs \n",
      "works revolution unfathered gildst languished expired play \n",
      "shalt aright oer west some slandering commence \n",
      "seldom appetite on sportive there tan feelst \n",
      "ruth tombs god only sings prison clears \n",
      "monuments about diseased monarchs recite then youth \n",
      "\n",
      "Temperature 10\n",
      "third selfsubstantial widow laughed essays painful clock \n",
      "dress showers stamped aprils onwards advantage withering \n",
      "says consider delight condemned humble redeem limits \n",
      "settled poet misprision separable souls receive sepulchres \n",
      "heat hallowed when admitted noted afterwards intents \n",
      "largess hems gains granting though hunted wronk \n",
      "merchandized thousand ever consumed astonished turns unkind \n",
      "famoused tired presage move roses purge hours \n",
      "crowning winters there offices betraying silver steeled \n",
      "confounding zealous thrall repent beds jollity aught \n",
      "phoenix hated alike lose succession slight tendered \n",
      "owners give clear had wealth tanned enfeebled \n",
      "maladies daily rolling mad we diseased lap \n",
      "fickle page eased need watch owst lesser \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set seed for emissions\n",
    "seed_to_int = [rand.randint(0, n_words) for i in range(seq_length)]\n",
    "# generate emissions\n",
    "pattern = seed_to_int\n",
    "temps = [0.1, 0.25, 0.75, 1.5, 2, 2.5, 3, 5, 10]\n",
    "\n",
    "for temp in temps:    \n",
    "    print('Temperature', temp)\n",
    "    \n",
    "    # generate characters\n",
    "    newlines = 0\n",
    "    words = 0\n",
    "    while newlines < 14:\n",
    "        x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        x = x / float(n_vocab)\n",
    "        prediction = model.predict(x, verbose=0)[0]\n",
    "\n",
    "        # sample according to temperature\n",
    "        idx = sample(prediction, temp)\n",
    "        \n",
    "        #index = np.argmax(prediction[0])\n",
    "        result = int_to_word_map[idx]\n",
    "        pattern.append(idx)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "        \n",
    "        if words < seq_length:\n",
    "            words += 1\n",
    "            sys.stdout.write(result)\n",
    "            sys.stdout.write(' ')\n",
    "            sys.stdout.flush()\n",
    "        elif words == seq_length:\n",
    "            sys.stdout.write('\\n')\n",
    "            sys.stdout.flush()\n",
    "            newlines += 1\n",
    "            words = 0\n",
    "        \n",
    "        # output result \n",
    "        \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
